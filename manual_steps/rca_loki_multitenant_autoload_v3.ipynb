{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ”Ž Loki (multi-tenant) â†’ Parquet â†’ Episodes (Auto-load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Window: 2025-09-10 13:22:19.780245+00:00 â†’ 2025-09-10 19:22:19.780245+00:00\n"
          ]
        }
      ],
      "source": [
        "# %pip install --quiet pandas numpy requests pyarrow\n",
        "from pathlib import Path\n",
        "import os, pandas as pd, numpy as np\n",
        "\n",
        "DATA_DIR = Path(\"data\"); DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "UNIFIED_DIR = DATA_DIR / \"unified_logs\"; UNIFIED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "END   = pd.Timestamp.utcnow()\n",
        "START = END - pd.Timedelta(\"6h\")\n",
        "print(\"Window:\", START, \"â†’\", END)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, urllib3\n",
        "\n",
        "LOKI_BASE       = os.environ.get(\"LOKI_BASE\", \"https://logging-loki-openshift-logging.apps.rhoai.ocp-poc-demo.com\")\n",
        "LOKI_TOKEN      = os.environ.get(\"LOKI_TOKEN\", \"<REDACTED>\")\n",
        "LOKI_INSECURE   = os.environ.get(\"LOKI_INSECURE\", \"true\").lower() in (\"1\",\"true\",\"yes\")\n",
        "\n",
        "if LOKI_INSECURE:\n",
        "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "_session = requests.Session()\n",
        "_headers = {\"Accept\": \"application/json\"}\n",
        "if LOKI_TOKEN:\n",
        "    _headers[\"Authorization\"] = f\"Bearer {LOKI_TOKEN}\"\n",
        "\n",
        "def _debug_response(resp):\n",
        "    return f\"HTTP {resp.status_code} {resp.url}\\n{(resp.text or '')[:300]}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loki_ping_tenant(tenant: str):\n",
        "    url = f\"{LOKI_BASE}/api/logs/v1/{tenant}/loki/api/v1/labels\"\n",
        "    r = _session.get(url, headers=_headers, verify=not LOKI_INSECURE)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loki_query_range_tenant(tenant: str, expr, start_ts, end_ts, step=\"15s\", limit=5000):\n",
        "    url = f\"{LOKI_BASE}/api/logs/v1/{tenant}/loki/api/v1/query_range\"\n",
        "    params = {\n",
        "        \"query\": expr,\n",
        "        \"start\": int(pd.Timestamp(start_ts).value),\n",
        "        \"end\": int(pd.Timestamp(end_ts).value),\n",
        "        \"step\": step,\n",
        "        \"limit\": str(limit),\n",
        "    }\n",
        "    r = _session.get(url, params=params, headers=_headers, verify=not LOKI_INSECURE)\n",
        "    if not r.ok:\n",
        "        raise RuntimeError(_debug_response(r))\n",
        "    data = r.json().get(\"data\", {}).get(\"result\", [])\n",
        "    rows = []\n",
        "    for series in data:\n",
        "        labels = series.get(\"metric\", {})\n",
        "        for ts, line in series.get(\"values\", []):\n",
        "            ns = int(float(ts))\n",
        "            rows.append({\"ts\": pd.to_datetime(ns, unit=\"ns\", utc=True), \"line\": line, **labels})\n",
        "    return pd.DataFrame(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Safe Fetch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[application] {k8s_namespace_name=~\".+\"}\n",
            "[application] rows 5000\n",
            "[infrastructure] {k8s_namespace_name=~\".+\"}\n",
            "[infrastructure] rows 5000\n",
            "[audit] {k8s_node_name=~\".+\"}\n",
            "[audit] rows 5000\n"
          ]
        }
      ],
      "source": [
        "def tenant_wildcard_selector(tenant: str):\n",
        "    try:\n",
        "        labels = set(loki_ping_tenant(tenant).get(\"data\", []))\n",
        "    except Exception:\n",
        "        labels = set()\n",
        "    for key in [\"k8s_namespace_name\",\"namespace\",\"k8s_pod_name\",\"pod\",\"k8s_node_name\",\"node\",\"job\",\"log_type\"]:\n",
        "        if key in labels:\n",
        "            return f'{{{key}=~\".+\"}}'\n",
        "    return '{job=~\".+\"}'\n",
        "\n",
        "def safe_fetch(tenant: str, start, end):\n",
        "    try:\n",
        "        sel = tenant_wildcard_selector(tenant)\n",
        "        print(f\"[{tenant}] {sel}\")\n",
        "        df = loki_query_range_tenant(tenant, sel, start, end)\n",
        "        print(f\"[{tenant}] rows {len(df)}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"[{tenant}] failed â†’ {e}\")\n",
        "        return pd.DataFrame(columns=[\"ts\",\"line\"])\n",
        "\n",
        "df_app   = safe_fetch(\"application\", START, END)\n",
        "df_infra = safe_fetch(\"infrastructure\", START, END)\n",
        "df_audit = safe_fetch(\"audit\", START, END)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json, re\n",
        "\n",
        "def _to_text(v):\n",
        "    if isinstance(v,str): return v\n",
        "    try: return json.dumps(v)\n",
        "    except: return str(v)\n",
        "\n",
        "def project_unified_stronger(df, src):\n",
        "    line = df[\"line\"].map(_to_text).astype(\"string\")\n",
        "    return pd.DataFrame({\n",
        "        \"ts\": df.get(\"ts\"),\n",
        "        \"source\": src,\n",
        "        \"msg\": line,\n",
        "        \"level\": \"info\"\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Concat/write"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unified rows: 15000\n"
          ]
        }
      ],
      "source": [
        "parts = []\n",
        "if not df_app.empty: parts.append(project_unified_stronger(df_app,\"app\"))\n",
        "if not df_infra.empty: parts.append(project_unified_stronger(df_infra,\"infra\"))\n",
        "if not df_audit.empty: parts.append(project_unified_stronger(df_audit,\"audit\"))\n",
        "unified = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=[\"ts\",\"source\",\"msg\",\"level\"])\n",
        "\n",
        "unified.to_parquet(UNIFIED_DIR/\"latest.parquet\", index=False)\n",
        "print(\"Unified rows:\", len(unified))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Episodes auto-load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episodes: 2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-10 19:10:00+00:00</td>\n",
              "      <td>2407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-10 19:20:00+00:00</td>\n",
              "      <td>12593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      start  count\n",
              "0 2025-09-10 19:10:00+00:00   2407\n",
              "1 2025-09-10 19:20:00+00:00  12593"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if 'unified' not in globals() or unified.empty:\n",
        "    if (UNIFIED_DIR/\"latest.parquet\").exists():\n",
        "        unified = pd.read_parquet(UNIFIED_DIR/\"latest.parquet\")\n",
        "        print(\"Loaded unified from file:\", unified.shape)\n",
        "\n",
        "def build_episodes(df, window=\"10min\"):\n",
        "    if df.empty: return []\n",
        "    df = df.copy(); df[\"ts\"]=pd.to_datetime(df[\"ts\"],utc=True,errors=\"coerce\")\n",
        "    df=df.dropna(subset=[\"ts\"]).set_index(\"ts\")\n",
        "    eps=[]\n",
        "    for wstart,wdf in df.groupby(pd.Grouper(freq=window)):\n",
        "        if wdf.empty: continue\n",
        "        eps.append({\"start\":wstart,\"count\":len(wdf)})\n",
        "    return eps\n",
        "\n",
        "eps=build_episodes(unified)\n",
        "print(\"Episodes:\", len(eps))\n",
        "pd.DataFrame(eps).head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
