{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# \ud83d\udd0e Loki (multi-tenant) \u2192 Parquet \u2192 Episodes (Auto-load)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "# %pip install --quiet pandas numpy requests pyarrow\nfrom pathlib import Path\nimport os, pandas as pd, numpy as np\n\nDATA_DIR = Path(\"data\"); DATA_DIR.mkdir(parents=True, exist_ok=True)\nUNIFIED_DIR = DATA_DIR / \"unified_logs\"; UNIFIED_DIR.mkdir(parents=True, exist_ok=True)\n\nEND   = pd.Timestamp.utcnow()\nSTART = END - pd.Timedelta(\"6h\")\nprint(\"Window:\", START, \"\u2192\", END)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Helpers"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import requests, urllib3\n\nLOKI_BASE       = os.environ.get(\"LOKI_BASE\")\nLOKI_TOKEN      = os.environ.get(\"LOKI_TOKEN\")\nLOKI_INSECURE   = os.environ.get(\"LOKI_INSECURE\", \"true\").lower() in (\"1\",\"true\",\"yes\")\n\nif LOKI_INSECURE:\n    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n\n_session = requests.Session()\n_headers = {\"Accept\": \"application/json\"}\nif LOKI_TOKEN:\n    _headers[\"Authorization\"] = f\"Bearer {LOKI_TOKEN}\"\n\ndef _debug_response(resp):\n    return f\"HTTP {resp.status_code} {resp.url}\\n{(resp.text or '')[:300]}\"\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def loki_ping_tenant(tenant: str):\n    url = f\"{LOKI_BASE}/api/logs/v1/{tenant}/loki/api/v1/labels\"\n    r = _session.get(url, headers=_headers, verify=not LOKI_INSECURE)\n    r.raise_for_status()\n    return r.json()\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def loki_query_range_tenant(tenant: str, expr, start_ts, end_ts, step=\"15s\", limit=5000):\n    url = f\"{LOKI_BASE}/api/logs/v1/{tenant}/loki/api/v1/query_range\"\n    params = {\n        \"query\": expr,\n        \"start\": int(pd.Timestamp(start_ts).value),\n        \"end\": int(pd.Timestamp(end_ts).value),\n        \"step\": step,\n        \"limit\": str(limit),\n    }\n    r = _session.get(url, params=params, headers=_headers, verify=not LOKI_INSECURE)\n    if not r.ok:\n        raise RuntimeError(_debug_response(r))\n    data = r.json().get(\"data\", {}).get(\"result\", [])\n    rows = []\n    for series in data:\n        labels = series.get(\"metric\", {})\n        for ts, line in series.get(\"values\", []):\n            ns = int(float(ts))\n            rows.append({\"ts\": pd.to_datetime(ns, unit=\"ns\", utc=True), \"line\": line, **labels})\n    return pd.DataFrame(rows)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Safe Fetch"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def tenant_wildcard_selector(tenant: str):\n    try:\n        labels = set(loki_ping_tenant(tenant).get(\"data\", []))\n    except Exception:\n        labels = set()\n    for key in [\"k8s_namespace_name\",\"namespace\",\"k8s_pod_name\",\"pod\",\"k8s_node_name\",\"node\",\"job\",\"log_type\"]:\n        if key in labels:\n            return f'{{{key}=~\".+\"}}'\n    return '{job=~\".+\"}'\n\ndef safe_fetch(tenant: str, start, end):\n    try:\n        sel = tenant_wildcard_selector(tenant)\n        print(f\"[{tenant}] {sel}\")\n        df = loki_query_range_tenant(tenant, sel, start, end)\n        print(f\"[{tenant}] rows {len(df)}\")\n        return df\n    except Exception as e:\n        print(f\"[{tenant}] failed \u2192 {e}\")\n        return pd.DataFrame(columns=[\"ts\",\"line\"])\n\ndf_app   = safe_fetch(\"application\", START, END)\ndf_infra = safe_fetch(\"infrastructure\", START, END)\ndf_audit = safe_fetch(\"audit\", START, END)\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Projector"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import json, re\n\ndef _to_text(v):\n    if isinstance(v,str): return v\n    try: return json.dumps(v)\n    except: return str(v)\n\ndef project_unified_stronger(df, src):\n    line = df[\"line\"].map(_to_text).astype(\"string\")\n    return pd.DataFrame({\n        \"ts\": df.get(\"ts\"),\n        \"source\": src,\n        \"msg\": line,\n        \"level\": \"info\"\n    })\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 4: Concat/write"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "parts = []\nif not df_app.empty: parts.append(project_unified_stronger(df_app,\"app\"))\nif not df_infra.empty: parts.append(project_unified_stronger(df_infra,\"infra\"))\nif not df_audit.empty: parts.append(project_unified_stronger(df_audit,\"audit\"))\nunified = pd.concat(parts, ignore_index=True) if parts else pd.DataFrame(columns=[\"ts\",\"source\",\"msg\",\"level\"])\n\nunified.to_parquet(UNIFIED_DIR/\"latest.parquet\", index=False)\nprint(\"Unified rows:\", len(unified))\n",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Step 5: Episodes auto-load"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "if 'unified' not in globals() or unified.empty:\n    if (UNIFIED_DIR/\"latest.parquet\").exists():\n        unified = pd.read_parquet(UNIFIED_DIR/\"latest.parquet\")\n        print(\"Loaded unified from file:\", unified.shape)\n\ndef build_episodes(df, window=\"10min\"):\n    if df.empty: return []\n    df = df.copy(); df[\"ts\"]=pd.to_datetime(df[\"ts\"],utc=True,errors=\"coerce\")\n    df=df.dropna(subset=[\"ts\"]).set_index(\"ts\")\n    eps=[]\n    for wstart,wdf in df.groupby(pd.Grouper(freq=window)):\n        if wdf.empty: continue\n        eps.append({\"start\":wstart,\"count\":len(wdf)})\n    return eps\n\neps=build_episodes(unified)\nprint(\"Episodes:\", len(eps))\npd.DataFrame(eps).head()\n",
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}